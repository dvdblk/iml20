{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Initialization of libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/home/bscuser/data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DKWL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FCHN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KDQP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FNWI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NKRM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111995</th>\n",
       "      <td>GSME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111996</th>\n",
       "      <td>DLPT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111997</th>\n",
       "      <td>SGHC</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111998</th>\n",
       "      <td>KIGT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111999</th>\n",
       "      <td>PGPT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Sequence  Active\n",
       "0          DKWL       0\n",
       "1          FCHN       0\n",
       "2          KDQP       0\n",
       "3          FNWI       0\n",
       "4          NKRM       0\n",
       "...         ...     ...\n",
       "111995     GSME       0\n",
       "111996     DLPT       0\n",
       "111997     SGHC       0\n",
       "111998     KIGT       0\n",
       "111999     PGPT       0\n",
       "\n",
       "[112000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Preparing data and One Hot Encoding.\n",
    "\n",
    "Taking into account that Protein molecules are a sequence, we have to split it for encoding every part of the sequence. Next comes the splitting  of thesequence by letters and using the One Hot Encoding approach. For encoding we used the One Hot encoder from the sklearn package. As a result, we received an array with 26 encoded categories for each row of the input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(word): \n",
    "    return [char for char in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first=[]\n",
    "second=[]\n",
    "third=[]\n",
    "fourth=[]\n",
    "for index,row in data.iterrows():\n",
    "    first.append(split(row[0])[0])\n",
    "    second.append(split(row[0])[1])\n",
    "    third.append(split(row[0])[2])\n",
    "    fourth.append(split(row[0])[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categories='auto', drop=None, dtype=<class 'numpy.float64'>,\n",
       "              handle_unknown='ignore', sparse=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split=pd.DataFrame()\n",
    "data_split[\"First\"]=first\n",
    "data_split[\"Second\"]=second\n",
    "data_split[\"Third\"]=third\n",
    "data_split[\"Fourth\"]=fourth\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n",
       "        'Q', 'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object),\n",
       " array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n",
       "        'Q', 'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object),\n",
       " array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n",
       "        'Q', 'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object),\n",
       " array(['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P',\n",
       "        'Q', 'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_data=enc.transform(data_split).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112000, 80)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Splitting dataset for training and validation. \n",
    "\n",
    "For calculation F1 metric dataset was split into train and validation subsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X=enc_data\n",
    "y=np.array(data[\"Active\"])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Training of model\n",
    "\n",
    "Taking into account the conditions of task SVC was chosen as the main approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=80, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "100800/100800 [==============================] - 1s 11us/step - loss: 0.2204 - acc: 0.9500\n",
      "Epoch 2/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0824 - acc: 0.9649\n",
      "Epoch 3/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0640 - acc: 0.9752\n",
      "Epoch 4/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0593 - acc: 0.9773\n",
      "Epoch 5/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0547 - acc: 0.9790\n",
      "Epoch 6/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0491 - acc: 0.9813\n",
      "Epoch 7/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0444 - acc: 0.9832\n",
      "Epoch 8/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0408 - acc: 0.9846\n",
      "Epoch 9/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0382 - acc: 0.9853\n",
      "Epoch 10/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0362 - acc: 0.9860\n",
      "Epoch 11/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0346 - acc: 0.9866\n",
      "Epoch 12/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0334 - acc: 0.9868\n",
      "Epoch 13/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0323 - acc: 0.9872\n",
      "Epoch 14/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0314 - acc: 0.9872\n",
      "Epoch 15/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0305 - acc: 0.9880\n",
      "Epoch 16/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0297 - acc: 0.9883\n",
      "Epoch 17/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0290 - acc: 0.9885\n",
      "Epoch 18/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0284 - acc: 0.9888\n",
      "Epoch 19/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0279 - acc: 0.9890\n",
      "Epoch 20/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0274 - acc: 0.9894\n",
      "Epoch 21/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0269 - acc: 0.9893\n",
      "Epoch 22/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0263 - acc: 0.9898\n",
      "Epoch 23/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0258 - acc: 0.9899\n",
      "Epoch 24/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0254 - acc: 0.9900\n",
      "Epoch 25/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0248 - acc: 0.9903\n",
      "Epoch 26/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0245 - acc: 0.9905\n",
      "Epoch 27/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0241 - acc: 0.9907\n",
      "Epoch 28/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0238 - acc: 0.9909\n",
      "Epoch 29/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0234 - acc: 0.9908\n",
      "Epoch 30/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0232 - acc: 0.9911\n",
      "Epoch 31/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0229 - acc: 0.9911\n",
      "Epoch 32/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0226 - acc: 0.9911\n",
      "Epoch 33/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0223 - acc: 0.9915\n",
      "Epoch 34/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0221 - acc: 0.9914\n",
      "Epoch 35/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0219 - acc: 0.9916\n",
      "Epoch 36/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0217 - acc: 0.9917\n",
      "Epoch 37/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0215 - acc: 0.9917\n",
      "Epoch 38/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0213 - acc: 0.9918\n",
      "Epoch 39/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0211 - acc: 0.9918\n",
      "Epoch 40/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0209 - acc: 0.9921\n",
      "Epoch 41/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0207 - acc: 0.9922\n",
      "Epoch 42/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0204 - acc: 0.9921\n",
      "Epoch 43/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0202 - acc: 0.9922\n",
      "Epoch 44/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0200 - acc: 0.9924\n",
      "Epoch 45/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0199 - acc: 0.9923\n",
      "Epoch 46/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0199 - acc: 0.9924\n",
      "Epoch 47/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0195 - acc: 0.9926\n",
      "Epoch 48/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0194 - acc: 0.9924\n",
      "Epoch 49/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0192 - acc: 0.9926\n",
      "Epoch 50/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0191 - acc: 0.9928\n",
      "Epoch 51/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0190 - acc: 0.9926\n",
      "Epoch 52/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0189 - acc: 0.9927\n",
      "Epoch 53/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0188 - acc: 0.9927\n",
      "Epoch 54/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0185 - acc: 0.9930\n",
      "Epoch 55/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0186 - acc: 0.9929\n",
      "Epoch 56/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0183 - acc: 0.9930\n",
      "Epoch 57/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0182 - acc: 0.9931\n",
      "Epoch 58/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0181 - acc: 0.9931\n",
      "Epoch 59/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0180 - acc: 0.9932\n",
      "Epoch 60/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0181 - acc: 0.9929\n",
      "Epoch 61/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0178 - acc: 0.9932\n",
      "Epoch 62/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0178 - acc: 0.9931\n",
      "Epoch 63/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0179 - acc: 0.9930\n",
      "Epoch 64/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0176 - acc: 0.9934\n",
      "Epoch 65/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0176 - acc: 0.9932\n",
      "Epoch 66/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0176 - acc: 0.9932\n",
      "Epoch 67/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0175 - acc: 0.9934\n",
      "Epoch 68/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0174 - acc: 0.9932\n",
      "Epoch 69/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0174 - acc: 0.9932\n",
      "Epoch 70/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0173 - acc: 0.9933\n",
      "Epoch 71/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0174 - acc: 0.9931\n",
      "Epoch 72/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0172 - acc: 0.9933\n",
      "Epoch 73/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0172 - acc: 0.9933\n",
      "Epoch 74/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0170 - acc: 0.9936\n",
      "Epoch 75/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0170 - acc: 0.9933\n",
      "Epoch 76/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0170 - acc: 0.9935\n",
      "Epoch 77/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0170 - acc: 0.9934\n",
      "Epoch 78/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0168 - acc: 0.9933\n",
      "Epoch 79/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0168 - acc: 0.9936\n",
      "Epoch 80/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0168 - acc: 0.9937\n",
      "Epoch 81/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0168 - acc: 0.9933\n",
      "Epoch 82/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0168 - acc: 0.9937\n",
      "Epoch 83/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0167 - acc: 0.9935\n",
      "Epoch 84/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0167 - acc: 0.9936\n",
      "Epoch 85/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0166 - acc: 0.9935\n",
      "Epoch 86/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0166 - acc: 0.9936\n",
      "Epoch 87/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0165 - acc: 0.9935\n",
      "Epoch 88/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0166 - acc: 0.9936\n",
      "Epoch 89/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0164 - acc: 0.9935\n",
      "Epoch 90/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0164 - acc: 0.9937\n",
      "Epoch 91/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0164 - acc: 0.9937\n",
      "Epoch 92/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0164 - acc: 0.9937\n",
      "Epoch 93/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0163 - acc: 0.9938\n",
      "Epoch 94/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0163 - acc: 0.9936\n",
      "Epoch 95/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0163 - acc: 0.9937\n",
      "Epoch 96/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0161 - acc: 0.9940\n",
      "Epoch 97/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0161 - acc: 0.9938\n",
      "Epoch 98/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0161 - acc: 0.9935\n",
      "Epoch 99/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0162 - acc: 0.9936\n",
      "Epoch 100/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0160 - acc: 0.9937\n",
      "Epoch 101/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0160 - acc: 0.9937\n",
      "Epoch 102/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0160 - acc: 0.9939\n",
      "Epoch 103/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0161 - acc: 0.9938\n",
      "Epoch 104/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0160 - acc: 0.9938\n",
      "Epoch 105/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0159 - acc: 0.9938\n",
      "Epoch 106/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0159 - acc: 0.9941\n",
      "Epoch 107/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0159 - acc: 0.9938\n",
      "Epoch 108/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0157 - acc: 0.9939\n",
      "Epoch 109/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0159 - acc: 0.9936\n",
      "Epoch 110/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0158 - acc: 0.9939\n",
      "Epoch 111/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0159 - acc: 0.9939\n",
      "Epoch 112/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0156 - acc: 0.9941\n",
      "Epoch 113/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0155 - acc: 0.9940\n",
      "Epoch 114/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0156 - acc: 0.9940\n",
      "Epoch 115/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0156 - acc: 0.9941\n",
      "Epoch 116/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0155 - acc: 0.9940\n",
      "Epoch 117/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0155 - acc: 0.9941\n",
      "Epoch 118/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0154 - acc: 0.9941\n",
      "Epoch 119/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0154 - acc: 0.9943\n",
      "Epoch 120/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0156 - acc: 0.9938\n",
      "Epoch 121/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0155 - acc: 0.9942\n",
      "Epoch 122/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0154 - acc: 0.9941\n",
      "Epoch 123/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0154 - acc: 0.9941\n",
      "Epoch 124/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0154 - acc: 0.9942\n",
      "Epoch 125/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0153 - acc: 0.9941\n",
      "Epoch 126/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0155 - acc: 0.9940\n",
      "Epoch 127/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0153 - acc: 0.9940\n",
      "Epoch 128/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0152 - acc: 0.9940\n",
      "Epoch 129/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0153 - acc: 0.9942\n",
      "Epoch 130/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0152 - acc: 0.9942\n",
      "Epoch 131/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0153 - acc: 0.9939\n",
      "Epoch 132/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0151 - acc: 0.9942\n",
      "Epoch 133/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0152 - acc: 0.9940\n",
      "Epoch 134/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0152 - acc: 0.9941\n",
      "Epoch 135/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0150 - acc: 0.9945\n",
      "Epoch 136/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0151 - acc: 0.9941\n",
      "Epoch 137/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0150 - acc: 0.9941\n",
      "Epoch 138/150\n",
      "100800/100800 [==============================] - 1s 6us/step - loss: 0.0151 - acc: 0.9944\n",
      "Epoch 139/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0151 - acc: 0.9942\n",
      "Epoch 140/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0151 - acc: 0.9941\n",
      "Epoch 141/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0148 - acc: 0.9944\n",
      "Epoch 142/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0150 - acc: 0.9940\n",
      "Epoch 143/150\n",
      "100800/100800 [==============================] - 1s 9us/step - loss: 0.0149 - acc: 0.9944\n",
      "Epoch 144/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0148 - acc: 0.9944\n",
      "Epoch 145/150\n",
      "100800/100800 [==============================] - 1s 7us/step - loss: 0.0148 - acc: 0.9943\n",
      "Epoch 146/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0149 - acc: 0.9944\n",
      "Epoch 147/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0150 - acc: 0.9943\n",
      "Epoch 148/150\n",
      "100800/100800 [==============================] - 1s 9us/step - loss: 0.0150 - acc: 0.9940\n",
      "Epoch 149/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0147 - acc: 0.9945\n",
      "Epoch 150/150\n",
      "100800/100800 [==============================] - 1s 8us/step - loss: 0.0148 - acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f25a1ed46a0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=150, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200/11200 [==============================] - 0s 29us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.02042468285065545, 0.9925]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val,y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Calculation of metric\n",
    "\n",
    "As a metric for the model we chose the F1 score. The score was calculated on the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462028030809874"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred=model.predict_classes(X_val)\n",
    "f1_score(y_val, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7. Reading and encoding dataset. Prediction of classes. \n",
    "\n",
    "The same endocder was used for training dataset. Predicted classes were saved in CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"/home/bscuser/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "first=[]\n",
    "second=[]\n",
    "third=[]\n",
    "fourth=[]\n",
    "for index,row in test_data.iterrows():\n",
    "    first.append(split(row[0])[0])\n",
    "    second.append(split(row[0])[1])\n",
    "    third.append(split(row[0])[2])\n",
    "    fourth.append(split(row[0])[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_split=pd.DataFrame()\n",
    "test_data_split[\"First\"]=first\n",
    "test_data_split[\"Second\"]=second\n",
    "test_data_split[\"Third\"]=third\n",
    "test_data_split[\"Fourth\"]=fourth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_test_data=enc.transform(test_data_split).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=model.predict_classes(enc_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"test_answer_DL.csv\", y_test, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
